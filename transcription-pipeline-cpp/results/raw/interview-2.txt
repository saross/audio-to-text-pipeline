 Your name and your current role and experience with semantic artefacts. Yes, I'm Nicholas Carr and I'm the, I guess, founder of Currawong AI, a small technology company. By training, I'm really an informatics researcher originally and then a data architect. I worked in government departments for many years. I worked in research as well, but now I run this company providing support
 and development of semantic systems, knowledge graph systems, either by themselves or in conjunction with AI systems to, well, government, but also the private sector. So we've got some private sector clients. So we, all of our projects are knowledge graph semantic web projects. Some of them also include AI. And which areas do you mostly work in? So I've got a bit of a background in the mineral
 and geology space. So personally, I know a bit of that stuff. So we do work with a number of private and government minerals or primary resource sector concerns, but we also work with environmental data. So departments of environment, that sort of thing. And occasionally we have projects that are unrelated. So projects in the legal space and so on. But today it's mostly been environmental, scientific and mineral space sectors.
 So in general, you might be able to like deeply comment on the trends in the earth minerals and environment, but you can see your experience outside of those areas. It's a specialty to be working in our technology and in our information space. So that will translate across. So if we were working in a different sector, like, I don't know, let's think of arts and culture,
 like arts and culture, you know, to some extent, their informatics and vocabulary concerns are no different to anybody else's, even though the domain is different. And I forgot, of course, a big one, I can't believe I forgot it just then, indigenous data space. So we've been working for many years on a couple of big indigenous data projects. And to some extent, the concerns are exactly the same. So catering for specialist indigenous interests in data modelling is the same as catering for farming or mining interests in data modelling to some extent. And then of course, there's all the specialists
 domain things that that particular domain has. But for instance, indigenous data governance, which is our big thing, is almost exactly the same as devolved data governance to any other community. And my PhD was in agricultural data, actually, and working with the farmers and their groups there, their particular interests are different to indigenous interests, but the way that they had interests and the way those interests were paid for, ends up being the same. Yeah.
 One of the questions I have noted, which I might jump to, since you're on that topic, is, well, no, actually, I won't, I'll come back to it. Put it in my head for later. Yeah. So RVA, what critical, what gap do you see that feeling in the Australian data landscape into the future, now and into the future?
 I think by its design, it the gap that it feels is what it was set out to do, which is, when you've got researchers, in particular searches, and I've been very clear about the difference between research and non-research vocabularies, right, but in the in the research space, if you are a researcher out there or research unit, and what you want to do is to do a bit of vocabulary work for whatever reason, either you're actually studying the mechanics of vocabularies themselves, unlikely, there's only a few research best to do that. But if you're, if you're researching
 in a domain, and in that domain, you need vocabularies to assist with that, that research, and even products and development from that, you need a place to manage and deliver and publish those vocabularies. That's what RVA does. If you're a small researching unit at just pick one, Charles Darwin University, Sydney University, doesn't matter where, even CSIRO, whatever. And you said, I want to publish two or three vocabularies, maybe a little data model, and I want them to be available, I want to be used, I want people to see them, maybe other people to interact with them and even co-develop them.
 If you didn't have RVA, you'd have to set up an infrastructure to do that. Now, my company sets up infrastructures like that for bigger units, if you're a whole government department, and that's what and you want a whole vocabulary infrastructure, we're going to build you one. But if you're a research group, it's ridiculous to think that they would build a whole research infrastructure or vocabulary infrastructure just for a two to three year project. They could even be a career researcher there who's the person in their unit that is doing vocabulary work every second or third year on different projects over 15 years. Again, you don't want to have to build a whole
 vocabulary infrastructure for that one person, you just want them to use a shared service. Now, there are some shared services which the commercial sector's got covered, email service, you know, we all use email, none of us have to go and implement an email server, you've either got a corporate one that you're using in your organisation, or you can just use Gmail, honestly, it's got you covered. But vocabularies is not so, there just aren't vocabulary services out there much. So at the moment, your only options are have a big corporate ones provided to you because you're in an organisation that does vocabularies or use a shared one somewhere.
 And in Australian research, your best shared bet is RVA, there aren't too many other options. So it does that, does that well. And it should keep doing that. Now, I know, I mean, obviously, when you've got something that's working well, there's a thought that you might want to expand it. And I leave that to the ARDC to work out what they think expansion could mean, if it's needed at all. But what I would say I have been a little bit disappointed about over the last few years is the
 not the expansion of scope, it's the expansion of use, I think expansion of scope is probably not a good idea. I think that expansion of scope, you know, should RVA do more things? Probably not. There are a million things it could do. Why doesn't it, for instance, start doing Bitcoin mining and hosting, you know, emails again, because those are just not appropriate. But the thing that I would wish it to do would be to expand the user base. So if there were 100 researchers who used it, if we thought that vocabularies
 I mean, maybe there's a natural limit to how many people using vocabularies in Australia there would ever be. But I would like to think that more people would think of vocabulary work as being useful to them and more available and that that number of users of RVA would grow. So over time, you would have, you know, members of all 40 or whatever they are, universities in Australia using it, Department of Primary Industries over here and that there would just be more of the same. So I don't fully know the numbers off the top of my head. Obviously, numbers have gone up for RVA, but I would rather hope that they've gone up more.
 I would rather hope to be seeing more vocabularies coming in from more different small units of people who are doing that kind of defined data work.
 What do you see help there and how should they help and could it be integrated a little better into RVA? What are your thoughts?
 It's probably the hardest thing to deal with in vocab. We all think they're easy. Oh, yeah, just have a persistent identity. It's just not that easy. You, in particular, Megan, know this. But for listeners of this later on, trust me, it's really difficult. And the reason it's all difficult is because you're trying to assign something which is a universal governed object to a technical specific resource. So the issue here is you're trying to say, I'm going to make this thing point to that thing forever, but that thing is small. It gets moved around. It gets edited, you know, and the thing that I'm trying to point it at is a university
 defined web address that's stable and persistent. So very, very difficult to align those things. But what I think should happen is that when you're creating a vocab in RVA, you should basically have a sort of a doesn't have to be a questionnaire, but it can be in just the way you create the stuff. You type in the name, what your vocab called, and then somewhere it says, you know, what kind of thing do you want going on here? Do you not care at all? And this is just you just experimenting. It doesn't really matter. So it'll just use a sort of opaque kind of local namespace thing. Or do you want this to be a
 really hardcore published thing? And you've got a persistent identifier that you want to use as the root, persistent identifier. Do you want to assign a persistent identifier to each individual object? Do you want someone else to handle this for you? All of those options, which we know from experience, can be useful in different situations, should be available. And the UI absolutely needs to do this up front. If we don't suggest options to people right up front, what happens is they make vocabs using editor dot RVA dot blah, blah, blah, blah, blah, a totally system non-persistent identifier. And that's
 what stays there for years. And I've had to patch up vocabs, many of them over the years, where for five years, a vocab's been running that's got a editor dot pool party dot, you know, completely non-persistent identifier, system specific, all of those things. And it's just winning it in that if someone was to take that service and that system away, those web addresses would be absolutely meaningless. So we've been lucky that the RVA system has been stable for many years. So that's allowed things that look like that. Well, it's allowed
 persistent system identifiers to be fairly persistent for some years, and that's been great. But there's zero guarantee about that. I mean, there's so many reasons why these things could change. So if they did, all of those non specifically established pits would be broken. So we must offer choices up front. Now, what I've done to try and deal with this is that for many years, the Linked Data Working Group has been, you know, running a persistent identifier service and many vocabs in RVA use it. However, they've never been coupled. There's never been an option to sort of do this all at once. It's quite a
 coupled process, and that's mostly just through lack of investment and time and effort. You know, it's not like there's any reason they shouldn't be. It's just no one got around to it. Now, last year, ARDC took over the technical management of the Persistent Identifier Service, but didn't take over the conceptual management of it. So the technical work that was done on the Persistent Identifier Service was established, but I still run that. Linked Data Working Group still runs that. RVA, not RVA, ARDC literally hosts the service but doesn't know how they work. It's opaque to them, really.
 That's the gov.au. That's link.data.gov.au. That's right. And so when people register persistent identifiers and then actually mechanically make them all work, I'm doing that work and the Linked Data Working Group is doing that work. ARDC is facilitating it but isn't really involved in any deep way. The only person who really understood that is Richard Walker on his left. Now, I said to the Linked Data Working Group a few months ago, look, we should have a facility so that people can automatically request persistent identifiers from Linked Data Working Group.
 from any other system, including RVA. Now, it doesn't mean that you're bypassing governance. What might happen is you might request a PID and you might be instantly told whether it's even feasible. So if you ask for one that already exists, absolutely not feasible. So if you start typing in /deaf/agift, that already exists. You can't have that one. So that's an instant. You can't have that. But if you said /deaf/my-favourite-workout-whatever, you might go, well, look, in theory, that's available to you. Do you want to request it? And you can go, yes.
 Now, it has to go through a proper PID governance process of being approved. But at least right off the bat, you've actually requested that thing. Now, even if you had to change it, put a number two at the end or whatever, it would be much, much easier having requested something to then change it to what you were actually allocated than to not have requested at all. It puts people in the mindset of actually dealing with the PIDs. So we've almost finished implementing this now. We have a test Linked Data Working Group API up that has all the PIDs in it. And you can make a request
 to it. And this will be revealed by May, beginning of May in our Linked Data Working Group meeting. We'll be going for approval then, which is we've built a new database. We've put all the PIDs into it. We've put all the governance material for the PIDs into it. We've put all the organisations into it. And now you can request a PID automatically. And we haven't worked out all the mechanics yet, but it'll come to the point where a client system like RVA could have five options for PIDs. Create your own local one, W3 ID, whatever. And one of them would be linked
 to .data.gov.au. If you choose that option, it'll say, do you want to request a PID? And you go, yes. What do you like to request? You type it in and you hit enter to go, sorry, that was not available. Or you go enter and it says, oh, that was potentially available. It will be allocated under review. Do you want to proceed with this? Yes, I do. So it will write that into your data. Now, you know, you're busy making your vocab. Isn't that lovely? And at some point you hit save on your vocab and then through some process yet to be determined, that PID's approved. Then there's no more for you to do. You've now got that PID in process.
 So it's working or actually, sorry, you requested that, but, you know, you put a naughty word in there. You can't have that. So can you change it to this? And you go, yes. And then you hit change and then we'll go and change it in the RVA system to that. So, again, it's emphasized the fact that you need a PID and there's a mechanism to get it. And from the user's point of view, they won't really see that it's any different to the RVA system. It's just another part of the RVA system. It is actually a different system under the hood because the Linked Data Working Group can assign PIDs to many other things, not just RVA.
 But that's the way the users would see it. It would be just more capability to the RVA system. Now, the issues here are that this kind of work, doing this kind of Linked Data Working Group thing, that's the kind of work that my company would do. And we would charge good money for that. I've been doing this for free because there is no vision from any government body in Australia to do this yet. It's come from initially research, you know, people at CSIRO saying you should do this. And now it's coming from me and a few others saying we should do this, looking forward into the future.
 But no one's paying for it. So we'll get there. It'll take a little bit. It'll take until May to have technically implemented. It'll take a month or two to actually. We'll implement the system properly, but we have to hand it over to ARDC to run it. So I think by July or August meeting, we should have a fully capable system. It'll solve a bunch of issues for ARDC in running the system. They'll be running a new Linked Data Working Group system rather than the old legacy one, which nobody likes. They don't like it. We don't like it. No one likes it. So it'll be technically implemented.
 It'll be easier and more capable and it'll have these things that you can now do. Automatically request stuff, automatically validate data, all kinds of stuff. But we're winging it here because there's no, other than me and a couple other people, there's no overarching plan to do this. It's coming about through the goodness of certain people being involved.
 Sorry to interrupt, but that being government related PIDS, do you think there's a role for an edu.au service that would be exactly the same really or point out to W3IDs or what?
 So my suggestion is always the same, which is let's complete the.gov.au bit. And when we're happy with the situation that that's it, then you can speculate and say, yeah, we should probably have an edu.au as well. Now, I think that a.gov.au and edu.au are quite sensible to have. You could have both. My suggestion would be to run them on the same infrastructure with the same everything or just, there's no point running two of these. We found, by the way, there's zero value in running the system.
 We did consider running individual states and territories.gov.au PIDS services. You can just run one. It's not such a big job. One for the whole country is totally fine. So running.gov.au and edu.au in the same place, absolutely fine. We did consider running an image.gov.au or whatever, some derived service rather than linked up data, it would be image. because there was a whole regime that was potentially being muted about persistent identifies for images. That was an ARDC project that was proposed, but never got realized.
 We haven't come to the limit of what .gov.au can do. We know that because this work that I'm suggesting now isn't complete. So can we auto allocate? Can we auto test? Can we allocate large numbers? Are people all familiar with this? Do they understand the value? All of those questions need answering in general for PIDS, whether it's a .gov.au.au or edu.au.
 Now, W3CID, my company and I are a contributing member of that consortium because we're in the PIDS space. And W3ID fills another role. It's an easy to get PIDS, but it's ungoverned and there's no guarantees about it long term. It's running on a couple of servers that the company is very kindly provided. So it's got less guarantees about the long term than the linked data working group stuff. I find it very useful. I use it frequently. It's absolutely not appropriate for certain purposes. It's not appropriate for Australian government. That's one thing.
 It's also probably not appropriate for something that you wish to be seen as Australian, if not government, but to do with Australia in some way. So there's a jurisdictional element. It doesn't have that. It's an international one. It's also not, as I say, it's under no government governance regime other than a totally informal one. I'm a governing member, but I could approve or deny PIDS. Someone wants W3ID/Coala. I just say, no. Then there'll be a fight about that. And there's no mechanism.
 Now it's been running on goodwill. It's got several hundred PIDS made there. It's all fine. But it's a loosely governed thing. So it fills a role. If that's what you want, you get it. But it doesn't fill all of the PIDS requirements that we need in Australia, even just outside of the gov.au one. So I think a .edu.au one would be a very good idea. I think that if a .edu.au one was established, then it should be the primary PIDS mechanism that's suggested for RVA. And RVA should, by default, allocate .edu.au PIDS.
 The technical way it should do it is exactly what I just described about the .gov.au. It's just the other option. So you go, yeah, I'll have a .edu.au one. So link.data.edu.au whatever, slash blah. And it will say, you've requested this. That's potentially available. It'll be reviewed. It'll come back to you. It has to, has to be reviewed. We just cannot have a auto allocation system. Even W3ID is reviewed. Every request, a human is actually seeing that thing. And you have to do that because otherwise you get not necessarily malicious, but just things like
 identifiers with unusual characters in them, spaces. Now you can automate as much of this as you like. At the end of the day, for humans not reviewing these things, you know, we're making decisions on PIDS that are going to potentially be around for 10 years. And they're going to do things like I had persistent identifiers requested slash def slash water. And you think, what's the problem with that? The problem is the vocab that it was being allocated to or the model was something to do with water, obviously. But that thing really doesn't represent the whole of water in Australia. It really can't. And so it's not sensible to allocate that.
 So my suggestion for that one was technically you would be allowed to get this PID, first come first serve. But my strong recommendation to the point of, I won't let you have it actually, is you need to narrow the scope to be commensurate with the scope of your actual object. So in this case, say it was water quality or water abundance, then it can be slash def slash water abundance or something like that. So there's that kind of narrowing that really only humans can do at this point. It must be implemented. And I think it's one of the PID creation and allocations
 and one of the hardest things to do with the vocabularies, for sure. Absolutely. I've got that hanging over my head, as you know. Absolutely. So this is why I think that if we make the technical systems more integrated, great. Let's go ahead with the .gov.au one and get that all working. .gov.au PIDs should only apply to a very small proportion of the vocabs in RVA because most of them are not government. In fact, you and I know they shouldn't be government.
 So having the capability, they're good. The fact that systems can request it, as soon as that's all working, yes, the ARDC could invest in then setting up a .edu.au. I'd be delighted to do that after we've implemented the set of changes for .gov.au. Once the tooling and everything for .gov.au is there, .edu.au would be dead simple. I mean, the rate with which we actually do individual PIDs is low. If we were to double, triple or quadruple the requests by adding other domain, by getting more people involved,
 all these things, it would make very little difference to the amount of work that we do if all of the tooling was in place. So I'd encourage it. I think that you could go to .edu.au as your default primary allocation thing, but it just has to be under a well-managed regime. So the collection level identifiers, I guess the question around the high level resource identifier, talk of should that have
 an ORCID ID? It should have some kind of ID. You mean for the whole of the vocab? Yeah, yeah. So if you've got a well-managed PID system, then RVA should think about assigning a whole vocabulary ID as well. Well, that's what the PID would be. Which actually I don't think it does at the moment, or it doesn't make you. It doesn't make you. So this is another area of discussion that's been going on.
 So there is no reason why a .edu.au PID couldn't be exactly that thing and provide semantic
 where linked data style mechanics under the hood. It can do both of those things as long as the thing is registered. The problem with, there is a perception that these linked data PIDs can't be like ORCIDs and DOIs. They absolutely can. The only thing they're missing is the registration aspect. So you may know I've written some papers on this actually, about the modes with which we allocate PIDs in the Data Science Journal a couple of years ago, a few years ago now. But also I wrote a PID policy, I've written several actually,
 I wrote one for the Geological Survey of WA, which I can send you. And what it says is that there are classes of object in their world that need different kinds of PIDs. So one class of object are major definitional objects. So whole models, whole vocabularies, profiles of models, those sorts of major items. And then underneath those are minor definitional items. So the individual items within a vocabulary and within a class within a model and that sort of thing.
 And then there are whole data sets that need PIDs. And then there are elements within data sets. Now the elements within data sets number in the millions, individual features within a data set, individual boreholes, individual records for an individual borehole in 100,000 boreholes in the borehole data set. So there's a huge scope there, but the policy is quite simple. And it basically says the allocation of the PID is at that major object level. So it's either a definitional PID or a data set, but there's actually no difference.
 So there's a major defined object and it's got metadata and it's in a registry and it has a control process there. They're all unique. We know who the owner is, blah, blah, blah. It's got a status, is it accepted, rejected, all that. So it looks just like RAIDs and PIDs and all that sort of stuff. But through the mechanics of the linked data PIDs, it can then cater for any amount of mini PIDs within that. So if you've got a data set that's got 12 billion entries in it, and that number is not accidental, there is such a data set out there, those 12 billion objects are all subsidies.
 And it's governed exactly like an ORC IDEA in a RAID, but it has the technical properties of being able to allocate PIDs within that. Now, the user of that can stuff it up. They can get this PID registered and they could issue 12 billion objects underneath that and then break them. But that's on them. There's not much we can do about that. There's only a certain amount of governance we can handle and we handle it to this major object. So back to answering your question, should we have PIDs? We should, but the PIDs should be the .edu.au.
 PIDs. We don't need another regime. We just need to have a regime in place. Some best practices in guiding users towards best practice in ways that actually they might not even have to think about it so much or understand it. And we've got eight years of that being established in an embedded working group, actually. I'm quite happy with the governance of the PIDs. It's the mechanics and time and investment that's been a bit lacking. But the actual theory of governance, the guidelines, the mechanics, the control body review group,
 we follow a couple of international standards for this kind of review. So the background standard is 11179, which is a registry standard. And then the other one is 19165, which is it's the same standard as 11179 with a bit more detail. It says it's for geographical objects, but it's actually for IT objects of any sort. And so we follow those standards in terms of life cycles and who reviews what, when and so on. But really, as long as the object is controlled, managed, I would also say not that this is in the standards, but that as much of the
 information about it is publicly available. So who registered it, when that's all public, that you can test against a whole set. So say there's lots and lots of PIDs registered, you have to be able to evaluate your request against those. It's not just an isolation, so that you don't collide with them, those sorts of things. As long as those things are in place, and there's a well managed registry, then the top level PID acts exactly like an Org ID and so on and so on. Now, mechanically, apart from being assigned to that thing, conceptually, mechanically, it is like an
 Org ID. If you resolve that PID, it will go to that object. But unlike an Org ID and a DOI, it'll have subsidiary resolve properties as well. So that PID plus other bits will go to a certain element within that object. So Org IDs can't do that because there's only one object there. An Org ID goes to a person and that's it. You can't say, for instance, resolve this Org ID to some particular portion in Nick's career. That doesn't work like that. Yeah. So I think we can do exactly what the ARDC occasionally requests, which is
 a RAID or Org ID style PID for vocabs, but it should be the .ed.au one. Yeah. Yeah. Very good. Yeah, I went a little deep into that, but that's good because I think it's an essential area that we need to think about. We have a question about scope in the areas that you work in. Does RVA support the predominant
 artifact types that you see requested within? We're talking about research, really. So basic Scos vocabularies or should we be catering for other things, mappings, ontologies, whatever? Yeah. What's happened over the years, it's mostly obviously the Simon Poxes of the world. So what they'll do is they'll say, OK, so the RVA is capable of Scos-style vocabularies, and then they'll try and push it around a bit to see what they can do.
 Now, this is partly because this is what they do. They're experimentalists, and it's totally sensible to work out what the range of the thing can do is. So we've seen over the years, the pool party and RVA systems being pushed to doing things like organisation registers and things like that. The problem with that is that it becomes bad practice real quick. And I'll give you the example. The OGC, Open Geospatial Consortium, they implemented their own vocab server that was a Scos vocab server only years ago. And over the years, they've tried to shield
 shoehorn more and more stuff into that stuff that's well beyond Scos vocabs. So what they now have is a situation where they've got a lot of definition material that goes well beyond vocabs, models, profiles, different semantic relations, all shoehorned into the Scos system. And it's a mess. And it's because the better mechanics for doing that kind of modelling are a non-Scos set of mechanics which the tool doesn't support. So they've forced things into being broader, narrow relations, which just are not that in real life. So this standard's relation to this other standard
 in their world or this building block. You don't even know what a building block is, but it's not a vocab. This building block relates to this other building block in some way that just isn't a Scos relation. So to force it into one is silly. And they've done things like they've built catalogues or catalogues of catalogues using Scos collections with narrower, broader relations. It just doesn't make any sense. So when an outsider comes to see this, they actually get confused by this model. What they should have done is they should have defined the model mechanics that they wanted and then worked on implementing the tooling to do that or just accepted
 that they couldn't do it or something different instead of shoehorning it. So we're unwinding that with the OTC now. We're implementing generalised support for modelling mechanics so that they can do that. So there's a limit to how many... So I think of Pool Party and Solm Scos+. It's Scos+ a few other bits and pieces which you quite comfortably do, but you get to a limit of that. Now, the big limit that I think that it would be nice to see Pool Party and other things do, or not Pool Party, RVA, is model publication.
 You absolutely cannot use Scos relations for that. You actually need... And it's not open-ended. What the OTC are doing is open-ended. They want a continuously growing model and they'd be trying to shoehorn into Scos. So that's a different task. But the thing that RVA could do is to say, well, we have a Scos publishing mechanic. We also need or could have a OWL or shackle publishing mechanic. Now, that's not open-ended. When you look at OWL models, we're not talking about an infinite set of properties and classes. We're talking about the properties and classes
 that define properties and classes because they're a model. So you can... And we have any number of examples of tools which will publish an ontology. But if I was to come as a researcher to RVA and want to publish an ontology and three vocabs, vocabs, done, no problem. There's no facility for them to publish the model at this stage. And if I think about what I see... And the mappings between terms as well. Yeah, they can do that. I mean, you can get two vocabs and you can use
 vocab relations between them. But what you can't do is you can't... Yeah, you can't define... You can't publish a new defined set of classes and predicates. You can't do the central task of semantic web model creation and publication through RVA. Now, what researchers have done over the years is typically is they'll publish vocabs in RVA and then they will make a model and then they will use a model documentation tool to document that model. So now they've got a human readable version of the model. Great.
 So where do they put that? And there's no facility. Now, those usually come out as web pages, actually. But that's where they also need a persistent identifier and a namespace for that thing. So then what they end up doing is they say RVA publication of the vocabs and... I've done this myself and many others have done it. We'll put the ontology, we'll document it online, we'll put it through a GitHub system and we'll assign a W3 IDE PID to it, something like that. So that's a mixed mode. Now, if RVA wanted to step up the offering that it was making, it would say, "Well, we published vocab
 and we do it well and we do it with persistent identifiers." Yeah, and I think that's a core task and it's absolutely valuable. But those two researchers who then go beyond vocabs into the next order of publication, which is actually model making, they should have the facility to publish models. And RVA could deliver that too. That's not to say that RVA would allow anyone to publish any type of thing. It's not any type of thing. It's specifically vocabs and new ontological models. Yeah, so that's what I think RVA could do.
 It could and should do as the next step. It could improve the vocab thing in the ways we talked about and there's mechanics underneath that, sure. But conceptually, when people in domains are modeling the domain, the first thing they do is create vocabs. The second thing they do, sometimes the first thing they do, it should be the second thing they do, is to start to create whole domain models. And it's the publication of those models, which there is no facility for that in Australia yet. And there is actually, is that very, very niche? Is there a demand for that stuff?
 Yes, there is a demand. You see it whenever some sector starts to get serious with this. So, for instance, in South Australia, they've only published 12 vocabularies and their vocabularies are fairly straightforward. They're all like, what file type is this thing? But a couple of the vocabularies are what you call science areas. You know, what area of geology is this dataset concerned with? OK, fine. That sounds straightforward. Those are just vocabs. But then they'll say, OK, well, now we want to publish a list of features, geological features. So we need three vocabularies to describe our data.
 OK, so now we've got a purpose, a commodity or a thing that we want and we've got a type. How do those two vocabs relate? They relate through a model which is not yet expressed. The moment they want to express that model, now they're into model publishing. And so what they're actually doing is they're now moving to somewhere needing to write down the model that relates their vocabs together. So you publish one vocabularies and then you write down the model that relates their vocabs together.
 You publish two, you publish three, that's all fine. When you start to get more than that, it's like, how do these vocabs relate to one another? That's the model. Where does the model live? Now, all of the work that I've done in the last 10 years to do with vocabs is model backed. There's a model somewhere that relates it. Sometimes it's trivial. You know, we're publishing a feature type and the only thing we need to know about is it's a geospatial feature and I just need a big classification vocab of just one. Conceptually, there's still a model there. The model is separating geospatial features from all the other things in the world and then this
 vocabulary of feature type applies to that, right? So it doesn't apply to me as a person, applies to that geospatial thing, sure. But usually it's much more complicated than that. Usually, you know, let's think of a rock sample. People say, OK, go model rock samples, fine. So there's three, four, five, six, ten vocabularies involved with, you know, what type of material is it? What's its purpose? Where was it collected? Who collected? All that stuff. But the thing that relates them all together is the model. So the model must be created at some point. And I think that vocabs are the gateway drug to higher order modelling. Domain modellers must make
 models and they start by doing vocabs and then they get an idea that, hey, we can formally define these things. These are working rather well. But the vocabs are on different dimensions of this issue. What are the dimensions? How do they relate? We can't just relate vocabs to vocabs with other vocabs. We can't just broaden narrower or close matched things because they could be on, again, the material of a sample and the purpose or the machine used to collect the sample are completely different dimensions. They have no Scoss relations between them, but they do have a model.
 And there's an increase use that, you know, there's the SSSOM folk as well testing that ontology. Oh, look, there's any number of... Yes, there's the mod ontology. Oh, yeah, there's heaps of documentation ontologies, but to have a facility for any of them would be the purpose. Yeah. I mean, they actually all come down to very similar to what RBA already has. You know, there's a top object in the model, which is an ontology as opposed to a concept scheme. And then a concept scheme is interested in one or more
 hierarchies with a certain hierarchy set of relations. And ontology is not interested in that. It's interested in definitions for classes and predicates. But it's actually the actual ontological definitions are very, very simple. Usually they are these are my classes and these are how they relate. And either what I'm doing is I'm making up the relations, you know, these have never existed in the world before, or I'm just rehashing schema.org or something like that or whatever. But the set of classes and properties, even though they are very simple to create, are very, very important.
 For that particular applied domain. I mean, most of the modeling I've done for, say, Geological Survey of Western Australia, most of that is just rehashing modeling from elsewhere. But what I'm doing is I'm taking the things of interest and I'm packaging for this scenario here. The majority of the work is in the vocabularies and so on. But the modeling is rehashing, but it has to be packaged. If it's not packaged, I don't know, going into this thing, you know, of all the things in the world that could relate these things, these vocabs together and all the things that I could say about rock samples.
 What does GSWA actually want to say about the world this model tells you? We want to know this, that and the next thing.
 I'm thinking things like, you know, Onto Portal Alliance things that could store vocabularies as well as ontologies. Is there a way that we could do this? Like the underpinnings of RVA understands the triple store, right? So you should, could you make it one big underlying system or is that too...
 But the issue is always the same. It's to work out exactly what the scope is that you're doing. The thing is, the idea that all of the semantic stuff is infinitely expandable is great in certain ways, but it's really problematic in other ways. So I'll give you an example. When we create vocabs for almost all of our clients, we don't use the full expressive power of SCOS. We actually use SCOS and a few other relationships here and there, but we limit it to the vocab profile. And the reason is that if you just strictly use the vocab closed world
 profile thing that covers 80-90% of all vocab issues and people should use that profile until they are sick to death of it and they know how it works perfectly and they specifically understand how they're going to expand it because the tooling for vocab is dead easy. Now we can have templates and work, excel workbooks and all kinds of stuff that works very well with vocab. If we said you can use any mechanics that you like in SCOS, that's a really difficult tooling thing to support. So the fact that someone might want to define three concept schemes in one vocab is really difficult.
 to support from a tooling point of view. And it doesn't usually add much benefit actually. So we say, listen, use vocab until you're absolutely certain that it's not covering your needs and that you can express in very fine detail what things it doesn't do. And then we'll consider using a different profile or expanded set of SCOS mechanics. So the same is true for ontologies. If you say to people, look, we're going to support the creation and publication of ontologies, but we're only going to support these things. You do that until they can very precisely
 articulate what it is that you can't do. Now, the actual art of ontology generation has been around for as long as they've been the semantic web. It's as old or older than SCOS actually. So to know what you can and can't do in an ontology, you just need to look at a tool like protege or top quadrants edge and it'll tell you, well, I create a class. What are the things I'm expected to do with a class? Now, one of the confusions that's come along the last few years is the rise of closed world models like Shackle. So Shackle, you can use Shackle as a complete model
 modeling language, just as you can Al. And some people use Shackle. Some people use Al. More people use Al than Shackle. Some people use a blend of the two. And that now becomes difficult really quickly. Now, I'm the co-chair of the W3C's Shackle working group, so I love my Shackle. I'm writing to Shackle. However, if we were thinking of what is the next thing that ARDC might offer researchers to do more semantic things, I would say just the traditional well-defined Al ontology creation and publication
 would be the next task. It is the task that you see various portals doing onto a portal, whatever. You can create ontology things. But you would say to them, the important thing here is to be able to create our models, not to be able to use every mechanic in model creation. To be able to create our models at all is not yet supported. So doing anything in that space is good. But to try and support every combination straight away would lead to
 a mega investment in a tool like Pool Party that can do all of this stuff. You're talking about creation as well as publishing. Yeah. And the thing is that you would need on your staff people who understand ontological tasks and creation mechanics better than anyone who's going to ask you a question. Now, I would suggest at this stage there is no such person on the ARDC staff. And I don't think you could get such a person anytime soon. What you could do is you could say, following other well-established model creation processes,
 we will support this one that this tool does. So onto a portal, whatever. And that's what you do. Then your task is just to learn what onto a portal or whatever supports in terms of model publication. I think this is a second order task. I think that we can do a lot of improving of the vocabulary space. But I do think that model creation and publication is a big deal. It should be supported. And to have a facility that's available to researchers in Australia to create models and publish them, it would reduce the effort required to create an ontology a lot. Because at the moment,
 if you're a PhD student or a researcher, go and create a model of bushfires or whatever. You're going to have to go and do that from scratch. And when you've done it, when you've created the thing, how the hell do you publish it? Even if they use a tool to create the ontology, there's no facility. So what they're going to do is they're going to publish it on a GitHub repository under their department's name, not using PIDs, blah, blah, blah. It's not integrated in any way with the ARDC and its offerings there. So to just even, in fact, even before creation, you would say publication, what you do is
 go and create an ontology. It has to be valid according to these things. And then you can publish it to the ARDC. Now, in the same way that we use ontpub for vocabularies, we use ontpub for ontologies. And all ontpub does is it just requires you to have an ontology with only one ontological object in it. So one ontology, not multiple. Classes and properties, created dates, publication dates, release dates, descriptions, names, labels, all that boring, boring stuff.
 And with that, it can then document neatly the ontology. Now, what does it not let you do? It doesn't let you do things like define bizarre ontology, property chain axioms and deep modeling things. But again, 90, 95 percent of all the modeling that's ever done doesn't require that. It just requires standard ontologies. So to support that profile, the ontpub, it's designed to be as simple to support as
 possible. And we support it when we're making models for people. That's what we do. RVA could do something like that and then work out what the offering is, maybe test the market to see if you were to supply such a thing, how much would it cost and how many people would like you to be using it. Now, if it was a static model publication facility, you give us the model, we'll just publish it. It's going to be valid and we'll publish it. That will cost you very little. It'll be very easy. And then the first comment you'll get or the second comment, the first comment you'll get is thanks for this.
 And the second comment is this is limited. I want to do a million things. And your response is, we'll do these million things when there's lots of people who want them done, not just one keen being researcher, because supporting researchers is a black hole. You can never satisfy a curious researcher. They always want to do more. That's their job. But to do some model support, I think, would be very valuable. Very good. Well, we'll come up to time.
 I'm keen to ask you a couple more questions about RVA like as it is, like what it could, except for we covered the PIDs pretty well, about how it could do better and whether that's going to be, we're considering is that going to be a major upgrade or minor incremental steps.
 I don't know. I've used your full hour. What was that question that you were going to ask me and then you decided you would hold off? No, that's probably pretty right. That was about the does RVA cover the scope requirements of the communities that you work in. I guess the only other one, the other domain you haven't talked about would be medical, which is perhaps a bit of a domain.
 They're a little more advanced and they've got their own pretty well-developed vocabulary service, from what I understand. They do. They've got all that. That's right, Onto Server and so on from CSIRO. It's exactly like you see in the major research. You've got the ARC and then the NHMRC. You've got, on the one hand, medical research funded in Australia and then all other research. Why? There should be one research body, funding body that funds a lot.
 We have two communities who've got medical and then everybody else. And the answer really is that medical is important and expensive, right? That's the real underlying reason. But conceptually from the ARDC's point of view, there should be no difference. So it would be nice to think that a medical researcher making a vocab would use the same facility as anybody else. But the legacy here is that they're in their own world. So I would leave it to ARDC to determine whether you want to get involved in that medical world. You know the people, it's those guys at CSIRO who do their own thing.
 I've been in the space. We've had zero collaboration between those two worlds. I've seen them presented certain occasions and we've presented to them, but there's never been any actual involvement. We're all to blame for that. But regarding the minor major questions about the RVA system, it's mostly to do with what you would think you would need to convince someone or other to keep things either going or make them better. Would the people who are funding
 all of this best want to say this RVA thing is a bit of a success. We just want to keep improving it and keep it going. And that's the real story there is that it's good. We want to make it a bit better. Or it's actually not performing and either it gets improved a lot or it gets shut down. Those are the kind of directions I would imagine you'd want to go in. I think that it's doing a good job. It's probably not very expensive if I think about the way it runs. I think it could be incrementally improved to be 20 to 30 percent better, whatever that, you know, pick some figure, right?
 It could be made better. And I think the betterness would come from PID allocations and things we've talked about there. I think the big, big story, which I don't know if RVA can solve in the short term because we can't even solve it easily outside of RVA with our own clients. It's actually a comprehensive vocab reference point. And RVA is absolutely not that at the moment. So if I wanted to work out what vocabs out there talk about coal, I could search for coal in RVA, but the search is limited.
 It also doesn't express the full extent of vocabs in Australia that have got coal in them. We know that and maybe it doesn't need to. It just says, no, no, no, I'm just, if you want coal in research vocab research in Australia, you've got to have it. But the reality is that the pool that people use for vocabs is much broader than that. So a facility that I would see is number one useful for everybody ever is actually a central vocab search point, which is almost just Google. But it would actually tap the entire holdings of RVA and all other known vocab research in Australia.
 And certain major collections of vocab internationally. Now that's a tool that ARDC could support. It would be a multi backend search facility across vocabs. Some things sort of exist like this. You've got the linked open vocab tool, but those are specialised to do with whole models. I'm talking about just simple, simple, finally any term in any vocab, anywhere that has coal in the ref label or the description, something like that. That would be extremely useful because after creation, the next question people ask is how do I find existing vocabs?
 And RVA doesn't answer that question other than its own domain. It answers the own question in its own domain quite well. You know, you search for coal in there, it's got that covered. But that just isn't the real story that researchers are concerned about. They want to know about coal in vocabs in general, not just in RVA. There are no researchers, as far as I can tell, who come along going, I'm going to use only vocabs from RVA. No, they come along saying, I want to use any vocab anywhere. I've searched in 10 other places. And RVA is 10%. So, you know, the only way we've been able to deal with this is to provide people, why don't you search for coal?
 And we've written down the 10 locations, AgroPortal, OntoPortal, RVA, Geological Survey of Queensland. So we're probably going to provide a private sector search across an industry specific set of things, the geology ones, we can do that in Australia. But again, that's only a small proportion of the total set of vocabs out there. So again, we don't have to know that there is an answer to this. But that is actually the big question. How do I find other vocabs and reuse them? That's the next one. Okay, very good.
 Excellent. I have two others more questions, but I'm going to let you go. No, no, you can ask me. I actually realised I don't have a meeting following this. So if it's such a couple of questions, we can keep going. Are you sure? This is just so much fun. I just want to keep going. It's all right. No worries. No, it's really interesting. It's good. There's heaps to think about. Yeah, just in terms of major, minor, upgrade.
 I have trouble with RVA, with the metadata being different to the metadata within the vocabulary file, the turtle, whatever it is. Can we do something about that? Can we make it and the ability to make that metadata linked and to be able to search across it?
 And not have to do the entry twice, basically, because I find that the metadata in the vocabulary file does not match the metadata within the ARDC metadata profile that it's requesting. So you can imagine a change that would solve that, that for most users, they may not even notice very much, but it would still be a major change. The issue here is simply the two different systems.
 And it's hard to know people's thoughts going back 10 years. But essentially, I think this is what happened. There's a tool to be used here, Sysvok. It publishes vocab. Okay, fine. But it's quite limited. And not just limited, we can't actually edit Sysvok because the tool, the mechanics and the programming now just ain't, it's actually archaic, and it's not supported. So what we'll do is we'll use Sysvok and then we'll wrap layers on top of it to achieve all these other outcomes, like a registry. So basically, RVA is a registry of vocabs. The actual vocab content and the registry content
 is not shared. And that's the fundamental problem. They're separate things. So I draft up my vocab content here, and then I, that's a bundle, and then I put registry information on top of it, and the versions are not aligned and all that stuff. So that's because of the limits of the tooling. Now, that was done presumably because there weren't too many options at the time. You go back in the years, you got a tool that can handle SCOS, great. But we need a registry, so we add the registry to it. Now, since then, it's been 10 years, the way we do all our registry
 of vocabs is exactly not that. It's actually simpler. All we do is this. We say all of the registry information must be in the vocab. So there is no information that's not in the vocab. So when you look at the status of the vocab, last published date, version, all that stuff is literally in the vocab. Now, if you want to only see the registry information, you don't want to see all the concepts. You just want to see vocab one, two, three, four, published date, whatever. That comes out of the vocabs. If you want to look inside the vocab and see all of its concepts, that comes out of the vocab. So what this means is that the actual registry
 content is just the vocab files. There's no other information allowed by design. It's pure semantic web here in that the metadata, the data, everything is just in these things. Now, you have to have a mechanism to actually control that source. And we just use source control. So we say there's a version control repository. All the vocab files are in it. And when something is in the registry, it's in there because it's in the version control repository. But the way that gets expressed out is the content of the vocab
 file itself. It doesn't express meta information about the vocab file. So the version control is only used to literally control the existence in the registry. The status, the created date, the version, all that stuff is a property inside the vocab file itself. And that is co-edited. It's mostly edited by the person creating the vocab. But the registry manager, the person who's actually responsible for managing this whole thing, they can and sometimes do go in and change the actual content of the vocab file. So you've created a vocab file, you've made 10,000
 changes to it, and you hit republish. But you fail to indicate a version change or a created date update. Now, the registry manager will go, "That's not appropriate. You've changed all this stuff. You must actually tick over the modified date at the very least." Now, some of it's discretion. Whether you want to indicate a vocab new version release or whatever is sort of up to you. But the modified dates are kind of absolute. If you've modified it, it's modified. So that kind of thing means that the focus is on the complete information is in that vocab. In isolation, it's complete.
 In a registry, it's complete. The status of the vocab with respect to the registry it's in must be in the vocab itself. And it's actually very, this sounds difficult. It's actually simpler. It's just one file. You think, "Okay, but what about if I want to do this?" You can always think of a complicated scenario, which might require more. You just don't allow that. It's exactly what I said before about allowing tricky things when you don't need to. 90% of what people want to do is covered by this model. Okay, well, hang on. What if I want an experimental version of it
 and a stable version over there and I want to blah, blah, blah. Okay, so at the moment RVA doesn't. It has a demo server. And that's the keys. You say, "Do whatever you want to do over here." But when you come to actually publishing for real, you've got one file, it's got a lot of stuff in there. You could say that if it's on the server, it is a stable published object. You can have stable and experimental elements within it. So individual concepts might be stable or experimental, whatever. You can have publications
 dates down to the individual concept level if you want. So you might have a vocab that was published two years ago, but this concept was only published six months ago, whatever. But that's still all in the vocab file. None of this requires a registry outside of the vocabs themselves. So the other thing that this would do is it simplifies the tooling enormously at the back end. So you say the source of all the vocabs is this version control thing. It all goes into one triple store, and then there's tooling to publish it out. That automatically means that the search will work on every aspect of the content, the metadata,
 the whole lot, because it's literally all in one database. So you do it, and it's full text indexed, all that stuff. So if you search for something with a prompted thing, it'll search for the vocab name, the definitions, the concept terms, the COL I mentioned before. If you search with a COL on one of our systems, it'll find if there's a whole vocab about COL, that'll come up first. Secondarily, any individual concept about COL will come up next. And then thirdly, any concept that's about COL but not COL, like the concept pref label isn't
 COL, but it talks about COL in the description, that'll come up. So there's a preference order in terms of the objects, but the entirety of the registry and the vocab, it's all in one. And that I think is the right solution. We're talking, let's guess how many vocabs there are in RPA. Let's say there's 500, but whether there was 500 or 1,500 or 5,000, it's still in the small database territory. So mechanically, it's actually a small system compared to very large corporate systems out there. So the actual results
 or the technical resourcing to support it is only a server or two, actually. It doesn't need to make clone after clone after clone of whole vocabulary systems like it's doing at the moment. It can just literally be one system as long as the registry information and the access controls are in place. So if you log on, you can only edit your vocabs. You can't edit someone else's. Those kinds of things must be supported. But to my mind, they can be supported through just literally one system with files in it and not much else.
 The RVA underneath, it clones each time someone loads a vocabulary, it implements its own database. So what it does is it uses a triple store and the triple stores almost all these days have really a similar setup. They say, okay, within one repository, I can have different named graphs, fine. And I can search and I can differentiate that, separate them there.
 But I can also have multiple repositories which are completely isolated. And you can understand a lot of databases do this. So sometimes they call datasets, sometimes they call repositories. But let's just take Gen up a second, which is what you guys use and what we tend to use. It's the leading open source one. So it's individual repositories are completely isolated. Each repository has a different sparkle endpoint and has completely isolated, you can't search across them. You have to implement another layer on top. So what RVA does is it creates a repository per vocab and it adds to the vocab
 content, labeling information and other bits and pieces. So you've got your vocab. So when you try and download a vocab, you don't get the vocab you put in, you get the vocab you put in plus standard labeling content and things like that. Now that's duplicative. It means that the same labeling content is present in every single repository and there's a lot of repositories. So what we do is we don't do that. We create a named graph per vocabulary and then all the supplementary information about labeling is in a single other graph.
 And it's shared. So every vocab in our systems out there, 90 percent of the labels they need are the same labels. So they're just in one place. Oh, this vocab needs a few extra labels. So you just get the person who's supplying the vocab to add. So when you download that vocab, you get all their concepts and all third party objects that they've referred to. If they want them to be labeled, they have to supply the labels. Fine. So it's a small overhead. But it also means that their vocab is now just in a named graph and that exact vocab minus all of the background labeling can
 be extracted if that's what you want. And it can be cross-searched across all the other things. So we're talking about this would be the same repository, the one underlying repository with individual graphs within that repository and within the graphs is the metadata. Exactly. Now, if you talk to say Richard who implemented this stuff years ago, if we had this conversation 10 years ago, there might have been concerns about the management of all those vocabs.
 In that one repository. So we didn't have an answer. It was guesswork to know whether it would be manageable 10 years ago because we didn't have experience. We do now. And we can say it is manageable. We've got vocab service with 250 vocabs. So that's Geological Survey of Queensland. They have no problems managing that stuff. Now, they are one unit managing it. So it's very straightforward for them. But say they had a set of users and they had to manage the vocabs on their behalf. They would need more procedures and management than they've got now, but not
 10 times more. They would need to have the access control in place, as I mentioned before, so that if you log in, you're only able to edit your vocabs, not anybody else's. And that's actually all in the version control side of things. In terms of the actual triple store, it's quite sustainable to have one big repository with all the stuff in there. And when I mentioned quite meaning before that the vocab content is actually quite small. If we look at other graphs that we know about, the biodiversity data repository is millions of times bigger than the vocab content.
 It's got literally billions of triples in it. Billions and billions. And so that kind of scaling, we know how to do those things now. We know how they work. We know what tooling supports them. We know how to keep the content isolated into different graphs. When I say we, there are lots of questions about this. It's not just me. So I can quite comfortably say that is it feasible for RVA to run on one repository with multiple graphs in it with all the vocabs in there to do comprehensive search and to contain all the registry information in the vocab content?
 Yes, it's totally plausible. It would be a simplification of the system you've got now. You'd have to rebuild the access control part of it. But you would reduce the number of background systems down enormously. Version control, database, access control, done.
 So I guess like doing a major upgrades, maybe not to cater for vocabularies is not ruling out that that system couldn't cater for models into the future.
 It would probably simplify. Look, Syslock and the other systems are quite legacy. Not just that, the actual RVA tooling itself, the actual registry is also a legacy application. Richard made it. There's no other examples of it. You could move to much more standardised tooling to do the RVA task as it's being done now. And then either in parallel or after or before or whatever you like, you could consider what model publication looks like. I would suggest that model publication doesn't need to
 use the same set of anythings, actually. What you do is you would get a model submitted. It would have to be valid according to a certain validation thing, which you could make up a submission thing easy enough for that. Upload your model. Is it valid? Yes or no? You know how to do that. Then you would store that model in version control and you would publish it out. But it doesn't have to be in the same system as all the vocabs. You might have a separate system for it. Or you could include it as yet another published thing in the vocab system.
 I think that we're talking 500 vocabs and at this stage zero models. In the next three years, you might have a thousand vocabs and five models or maybe 50 models. But the scales are such that I would work out what would be needed for a minimalistic model publication and test that out and just keep it outside of the vocab thing. And when you get to the point of having published thousands of vocabs and hundreds of models, then you might say, OK, we can actually combine those things. But I think there could be a very simple model publishing mechanic.
 It's the mechanic that we already see people doing by themselves. It's just that the RBA would support it so that the model is all in one place. You basically make a model registry. It's a big central version control thing and you publish those models. You statically create documentation for them and you publish them with persistence identifiers. That to me is a very simple task. We've done it to death, but the RBA or ARVC could support that. But that doesn't really impact the changes that you suggest here for the RBA mechanism itself.
 It's related to it and it could consume it one day, but I would just test the waters and do them separately there because we don't know if you would offer a model publication thing, maybe nobody comes to you with models and then you think after two years, but three models, they're all from Nick. Who cares? You know, just keep to the vocab. So I would be cautious about the model public. I would take what I said with a pinch of salt, just see if that's really demand. But on the vocab side, yeah, I think just as a risk mitigation thing for long term technical support, you would want to change the RBA system.
 There's a bunch of standard tools, servers, registries, tooling available now that you could select from, evaluate, which would be the next phase.
 I mean, forget access control and things on top of it. If you just did that and said, going forward, we're going to manage access control on a GitHub style pull request mechanism where you put pull requests in to create new vocabs. You can actually put a pull request into someone else's vocab and then the administrator would say, no, you can't do that. So that kind of GitHub based management is super well known by all your developers. And it would take very little effort to set up a governed access management thing here. The only question you might have is,
 is that sensible for all of your users? Are they all going to jump on board with things like pull requests? So that's when you go back to your graphical user interface, start editing in PoolPali or whatever. But the results of that editing might be in the GitHub thing so that the management is still there in GitHub. But just implementing GitHub and pick your favorite open access triple store, probably for Secchi, but could be RDF4JE, either one. That covers a lot of what you want. And then it's the publication mechanism out here.
 Which Cisco is currently doing and could still do, or you could use another one and there's several. But the thing here is to just reduce the number of custom components you've got down. It's like we used to have all different kinds of version control mechanisms. Nobody uses Mercurial anymore. Nobody uses Turtle SCN. We all use GitHub. What was the other one? RDF4? RDF4JE.
 That's the other big free open store, open triple store. There are lots of triple stores and there are other ones also that are open source. But for Secchi and RDF4JE, the two big ones, there are commercial ones as well. There's Neptune and things like that from AWS. But you guys are already running for Secchi. You're probably running more instances of it than you realize. We've implemented very large scale commercial and open source triple stores. And our general feel is that
 you would have to have very specific requirements not to be able to use for Secchi. So unless you can articulate very carefully what it is that for Secchi isn't doing for you, "Oh, I need this kind of special index that GraphDB provides." Unless you can articulate that, you can use for Secchi. And for the projects of the scope and the style and the size we're talking about here, like one instance of for Secchi, a reasonably well instance would cover the entire RVA database of all vocabs. And that's because we have
 lots of examples of this. We have GSQ's 250 vocabs in one system. No sweat. It's a tiny system and it's handling it fine. If RVA had 2,500, it would still cover it. So is a registry tooling on top of the Secchi? You've got the Secchi underneath. So for Secchi's database, you would have to implement the registry. Now, the content of the registry would come out of the individual vocabs. But the way that that
 registry access control and so on is managed would be some version of what you have now, but implemented under the hood differently. I mean, all it would really do is that someone logs in and when they log in, it just limits their view to their artifacts. So it just looks at what they've created and so on and what they entitled them to match. It's exactly the same as you've got now, but it's drawing all of its content from the vocab, not from a separate database, which I don't even know what the database is that you guys have.
 But it must be some other kind of Postgres database that's doing that. At one very quick last question, the API stuff. Do you have any comments on APIs and standardization of them or what we're using, what we could do better potentially? I've probably used your APIs more than anybody else and I haven't used them that much. So the API that I've wanted to use for some time is
 the search API so that I can make a tool. I have made this tool several times, but I've never found a long-term requirement to support it, which is I got a comprehensive vocab search tool here. It searches my repository number one, my repository number two, RVA number three. And so I've made that tool. It's a single web page and it's existed for some time, run for a few years, no one cared, shut down. Another API that I've used is your creation API, where I'd say I want to create a vocab on my system
 here and I want to publish it through my system and then I want to co-register with RVA. So I'm going to push the registry information to RVA and that's doable. It's been done. But again, we don't have enough people who want to do that to keep supporting. I think we'll get there. I think there's enough vocabs coming out of geological surveys and so on to co-register. By the way, this is another reason for the separate registry and the vocab thing is the idea that you would register a vocab that's not in the RVA system, but it's somewhere else.
 So it's a reference to it. That can actually also be achieved with semantic content. You literally just create a vocab file with the registry information in it, but when you click on it, it resolves somewhere else. So I think that even that level of oh, but the registry should contain things that are not stored here, that can also be achieved through the actual, it's a blank vocab, basically, that points somewhere else. That's fine. Well, that could be useful for what you were saying about being able to search cross when someone comes
 on search across. Exactly. In the best case, what would happen is you would say to someone, look, if your vocab is in the field of research, but it's published elsewhere. So the geological survey at WA, they publish their own vocabs for themselves in the state of WA industry. Fine. But there's nothing stopping them co-publishing, not just referencing, but co-publishing vocab in RVA. So then what you do is you take the entire vocab and you send it over to RVA and it comes out through the RVA system. It's in the triple source. It's searchable.
 And if you click on a link, it'll come back to the home system. So that's also been clear. So we know that that works fine with the registry APIs. But again, we just haven't had the strong requirement to maintain that tooling. So back to your original question about the APIs. The APIs at the moment are quite sufficient, but I don't think that they're widely used. I think I've used them a bit and I'm probably one of the few, or not just me, but the clients that we work for, probably one of the few users out there.
 So we're seeing some standardised vocab APIs being made now, the mod API and that sort of thing. And I think that RVA would need to support, it does now and would keep needing to support standardised searching across the vocabs. How do you do that? Sparkle endpoints of the obvious one, that lets you do anything. But the very next one that's not a sparkle endpoint, that is, as they say, more developer friendly or something, would be some other API. At the moment, the other API is a standard full text search API,
 the semantic one that Richard implemented, which searches across your vocab, your things in a certain way. You can't, for instance, specifically select Geoscience Australia as a publisher in RVA at the moment. You have to search for the phrase Geoscience Australia, and then from the results, choose the one that is the publisher, as opposed to a vocab that has the words Geoscience and Australia in it. So an API that wasn't a sparkle API, that was a somewhat standard vocab search API would need to be supported. And there's candidates now for that,
 10 years ago, the mod API being the main one. So I would say that going forward, you'd want to support that. Obviously the vocab tool that we implement is poised to support that API as well. We've been running a vocab search API for 10 years, and we've involved in the mod stuff. If they're going to standardise it, we'd support it. The other one is the OGC records API. It's just a catalogue API, but it works fine for vocabs. So we already support that one. So there are a couple of candidates there that, and where this comes out is that, so where we see,
 it's less true for RVA, but when we implement vocab systems, they are often required to be used by downstream systems. So I mentioned the geological server, South Australia, they've got their vocabs over there. They have two or three systems which must derive vocab content from that. And therefore it must use an API that that thing supports. So we have to have implemented a system that has certain APIs in place. If those APIs were standard, either OGC records APIs or mod APIs, that would be better. We haven't had that opportunity before, but going forward,
 commercially would say, here's a vocab server that we can supply you, and it uses the same API as the RVA one. So if you wanted your system to draw from both those places, it's the same API two times. Yeah. But yeah, I don't think, I think this is an easy part of the conversation, actually. The APIs are, honestly, the developers can make stuff much more easy than they can deal with, say, the registry issues and the PID issues. Yeah. Yeah. To me, the content one seems a bit messy.
 Your insights being useful, different, pragmatic, I guess, is that we could potentially get into a lot of trouble trying to cater for the minority at this stage. Yeah. And you want to help researchers out. But the thing is that every researcher is a unique special flower doing their unique special flower things. And again, just talk to Rowan about the things that he's had to do
 to support just Simon Cox, you know. And Simon's a power user, and he's a lead user, or was a lead user of all the stuff. That's true. But what he wants to do with Pool Party is not what most people want to do. And if what you're doing is trying to support the majority of the people, the majority of the time, you don't need to support Simon. You need to support the fundamental, so getting the issues that you identified, the metadata better, the PID allocations better. Simon doesn't care about that. He understands that stuff. He understands that. He doesn't need to be supported. But everybody else does.
 So getting the PID allocations and the metadata better is a more important task for RVA as a system than catering specifically for Simon, I think. And now, Simon obviously isn't with us in this research phase anymore. But if a vocab researcher comes along, I don't think RVA is the tool for them. If they were searching vocabs and what vocab should do, then they're in that world and they can use protege and they can use the technical tools there. But if they're a person who isn't a vocab researcher but needs to make vocabs, that's your target, because that's the point.
 So it might be pointing those power users, the protege and what users, off to pathways for publishing their models and ontologies.
 So that is the question that you don't want to answer in RVA. You want to say to that person, what you need to do is to write search papers about that and to essentially make your own specialised tooling that will show off that power. There are generic semantic web publication tools which might go somewhere there. But if they really show off something new, they need to go and make specialised experimental tooling to do that. That is not your job to support that, because that is vocab research.
 As opposed to vocab use. And RVA is research data infrastructure, not the making of research tools, I think.
 RVA does, for instance, is it'll auto-handle certain kinds of properties. So from your central object, the concept scheme or a concept, whatever it is you're looking at, really any predicates that you want to supply for that, as long as they are not, if the predicate points to a literal object, easy. It doesn't matter what the predicate is, it can label it. If the predicate points to a blank note with certain elements, it can handle that down to a certain depth. What it can't do is it can't say, here's a concept that points to another concept and a long chain of really difficult stuff.
 It also, the big thing it can't do is it can't work out what the central or important objects are unless you tell it. So the vocab profile fundamentally, apart from mandating certain kinds of elements, it fundamentally says that in a vocab, the number one object is the concept scheme. And then the number two type of object are all the concepts in the concept scheme, and they must be related in this particular way. So that means that when we encounter a vocab file, we know where to start. The problem with another kind of fancy-pants model is you don't know where to start.
 So it's a weird graph. Where's the entry point even? But if you know that the entry point is the SCOS concept scheme, yeah, you can add, this is the SCOS plus, it's the plus. You can add any straightforward predicates and properties to the concept scheme or to the individual concepts. And again, if SCOS solves 70% of all vocab problems by itself, then SCOS and a few other basic vocabulary solve 90% of them. And SCOS plus everything you've ever seen, as long as it's only applied to the concept scheme and the concepts, solves 99% of them.
 vocabs wise, it's only extreme cases that would go beyond that, where the only way to solve it is to have a combined object that's got 15 different concept schemes and a special object called a concept scheme parent in there that I've never heard of before. There's only very rare modeling cases that you do that. Now, as I mean, I'm actually a modeler by training, right? So modeling is actually what I do beyond this stuff. And usually the people who do those kinds of really complicated models, they're in one or two camps, they really know what they're doing. And this is really difficult stuff, or they don't know
 what they're doing, and they make me a hash of something that could be much simpler. Yeah, yeah. Oh, no, really? No, it's good. It's good to know. I mean, it's easy to stuff up a simple vocabulary, as you know, as you've seen me do. And I've got stuff in RVA still to fix. And so if people can be guided towards that basic best practice, that would be very useful. So Les is working for us. I mean, his job, he's doing training modules on how to do vocabs and things like that.
 But his job, he does two jobs, he works for us and he works for a government agency part time. His government agency job is 100% making one vocab. It's a very big vocab. But the actual expressive parent of vocab is just scos and a couple of other schema.org properties. The effort is not in the representation mechanism. The effort is in actually acquiring the vocab content and being thoughtful and organizing it. But the actual mechanics that he needs are just scos, schema.org, a couple of properties to do things like say,
 So this is the hierarchy and this concept comes from these people we got at this time. It's all it's registry stuff. So that's that's the mechanics he needs for a very, very large government vocab of thousands of terms. It's got a team of five people working kind of full time on it. You know, it's a big deal. But the actual mechanics are quite simple. Even being able to point people towards basic good metadata they might find useful, you know, some pro stuff, things like that, if they need it. Yeah, there's lots you could do.
 To make vocabularies better. The secondary purpose of the vocab profile is to communicate specific requirements on metadata to achieve a purpose. So what vocab says is that the fundamental thing is there's only one concept scheme for vocab. Let's keep it simple, folks. Don't muck around. You can have any number of concepts in there. They've got to be in one hierarchy, not two hierarchies. OK, fine. You can have a place, a poly hierarchy. So a concept can be in multiple places in the hierarchy. That's fine. But there's a single hierarchy that every term is in. There's no isolated terms. You can have any number of collections.
 OK, that's fine. And then all the other restrictions are just on basic metadata, the primary purpose of which is simple description. So created dates and things like that. The secondary purpose is all about the origins of the concepts. So vocab really just says every concept must tell you that what vocab it's in. So I'm in this vocab and they must be, otherwise I wouldn't be able to see them. But secondarily, they need to tell you where they were defined. Were they defined for the first time in this vocab or were they defined somewhere else? So the reason for that is that
 the thing I've been trying to solve is reuse. So we see a vocab here. It's one concept scheme. It's got 100 terms in it. Eight of them are defined in this vocab. But the other 92 are defined in other vocabs. And I'm just bringing them in. But I want to tell you that I'm bringing them in. Now you would say, "Oh, but doesn't URI do that?" You resolve, "Yeah, let's get real about people and machines here." People and machines and tech heads would resolve the URI, find that it goes to another vocab and go, "Oh, yeah, I see this comes from another vocab." But a human user looking at the labeled content isn't going to see that. They're not even going to notice or care about
 the URI. They need to be told very explicitly, "This term comes from another vocab." So the vocab insists on saying, "I'm present in this vocab, but I was actually defined somewhere else," or, "I was defined here." So that's all vocab does. Now that's a recommendation for particular purposes. You could also say something like, "Look, in Australia's research community, we need a little bit more metadata than that. We need metadata to do things like allocate fields of research codes and proportionate funding bodies, and which
 organization you're from." So then you would say, "Okay, there's a profile of VocPub called the ARDC's VocPub profile," which I've advocated for many times. And what it would do is it would say, "It's all the things we just said about VocPub because we want cross-use and VocPub's generic, so that's all cool." But the RVA insists on a couple of other fields of metadata to achieve purposes which VocPub in general doesn't have, and they are. Every vocab must be allocated an FOR code. This is for our accounting. Every vocab must be assigned a... Not a creator, because that could be an individual
 person, but some kind of supporting unit of the creator that is a research organization. Basically, what we're looking for is the sponsor of that vocab. Who's the sponsor? It's not someone's pet project. This is a Research Australia theme. Therefore, the entity that supports it must be from this list of known research entities. I think as researchers, citations would be useful. All of these things. So you can imagine that there would be... To encourage folks to get them up. Absolutely. They need to be able to be cited.
 Exactly. So I would say there's probably about only four or five editions that you would make to VocPub that would take it from generic VocPub to ARDC VocPub that would enormously assist the registry. Now, things like registry statuses and so on are not mandated but are possible in VocPub. But in your case, you'd absolutely want to mandate that. You'd want to say, when you're creating vocabs and publishing them through RVA version 2, the status of the vocabs in this registry and the items within
 it and so on must be present. Now, the status in the registry is simply that it has been published, really. So the user doesn't really need to fill them out. The system could do it. But from a validation point of view, every vocab must have such a status. If it's been proposed to the system but not yet published, it's literally submitted. If it's been accepted by the system and published, it's now stably published through RVA. So those kinds of... Again, probably four or five fields of metadata. There's any number of things they could have, but I think that there's only a few that you would need to
 really make a difference to your own accounting around the vocabs and management of them. Yeah, no, it's good because now you've gotten it going well over time but got it a really important topic around governance and people's trust in the resources in RVA, which at the moment is minimal. That decision was made for various reasons, but what's the minimum stuff that is a requirement?
 That's going to build trust in and the usefulness of the resources. Yeah. Let me show you one. If you let me share my screen, let me just show you something. Meeting info. No, it's not... You can't share yet. All right. Well, look, why don't you... No, it doesn't say share, but look, why don't you bring this up and I'll just send you the... Who can present? Oh, here you go.
 Everyone, it says now. Wait a minute. Yep. And I've finished with questions for you, so... OK, well, look, this is the only thing I'll show you. I mean, we could talk about this forever, but this is the kind of thing I want to show you. So this is the Geological Survey of South Australia's system. Now, this system was actually made two years ago. So from our point of view, it's old and it needs to be updated. It was made two years ago, but they had a pause on the project and it only got published a couple of weeks ago. But all I want to show you is this is a registry of vocabs right now.
 So the information you see here is experimentally what they want their registry to contain. So what do they want to contain? The name of the vocab, the custodian, which is kind of boringly... It's mostly the Geological Survey of South Australia, but there's a couple of others. There's Carawong. Here is CGI and here's an ISO committee. So it's not given that they're all South Australian vocabs, but they use them all. It's this derivation mode, which is proposed, but you can see not fully implemented here. It just tells you whether this vocab
 is a directory use of an existing vocab, whether it's their own vocab or whether it's a subset and extension of an existing vocab. So this gives us a fundamental insight into whether this is one of their custom jobs or whether it's pinched from somewhere else. And then there's the standard registry status here. Now, the point about this is not that RVA would have this information, but this information is... It's not mandated for vocabs in general, but it is mandated for their vocab. So they've got an extension to the profile to require
 a custodian, a derivation mode and a status to be included in their information whenever they create a vocab. Now, if we go to the Geological Survey of Western Australia, they have a slightly different set. It's not very different, but it's slightly different. Title, description, status, derivation mode unfilled, you can see, and themes. So their vocabs are themed according to a theming vocab.
 You can imagine that RVA would have, again, research codes, research unit, publisher, individual researcher, so that you could find all the vocabs by my favorite researcher out there, whatever. So you could think about that. Now, search would find you these, but actually just the listings and so on is usually where it's at for discovery. People look down this list and they can see these are stable, these are accepted but not stable, this is their categories, on and on and on. So the point is that we could extend or you could extend the vocab model
 to do what we mentioned before to ensure that all of the registry and governance information that you need is actually present in the vocabs themselves. And then a combination of the original author of the vocab and the system would actually write that out. So again, you don't really need to ask them what the submitted date is, the system can work that out. By the time they hit send into the system, it will stamp in the system date. And when it gets published, that's the accepted date. So a lot of the stuff you could do for them. But I think that in the vocab context,
 we could see everything we need. And again, the difference is to validate what's in a vocab, that's a normal shackle validation mechanic, as opposed to a custom registry mechanic somewhere else. So imagine that all funding goes away and RVA's put on life support for five years. If you just maintained the GitHub repository with the content in it, triple store would be nice. But if you just maintained GitHub, you literally didn't have any other systems except for GitHub. You could still guarantee that you had vocabs that were all needed
 and neatly organized and managed because you could shackle validate them. That costs you nothing to do. It's free tooling. And the content of the vocab files is all you need for that. So if you've got the validator present and the mechanic to validate them, you don't need other systems. Literally the cheapest vocab offering you could ever make anyone is we're going to manage this GitHub repository with this validator and these vocabs in it. We're not going to help you search them. None of that stuff. In fact, GitHub search isn't that bad. But we're not going to publish them in any way. It's just that we are going to maintain their presence in this registry.
 That would be the least offering that you can make. And it's still quite compelling because shackle validation is amazing. You can just do anything. Yeah. And it won't be built on bespoke code upon code that when a particular person leaves, then you're stuffed. Yeah. And all of the work that we've done, we've spent several years now writing up the pres system. But what we've ensured is that there is no special anything that pres needs other than a normal sparkle endpoint under the
 hood. And the reason for that is that if you implement our system on top of a vocab, on top of a triple store, and then we go bust or you get sick of the tool or you just don't want to like it anymore, there's been no special anythings that pres has used that have forced you to vendor lock in in that point. It's an open source thing anyway. But the point is, it's just using a sparkle endpoint. So you can swap out the backend database pres keeps working. You can throw away pres and pick up sys lock if you want or something else that respects that interface. So we've been very, very keen to ensure
 that the management of resources interfaces get version control, that the search supply endpoint is a sparkle endpoint. Whatever you can have, you can have open search, you can have CQL, which is a spatial search language, all of that stuff implemented on top of sparkle. Sparkle lets you do anything. So we've maintained these interfaces such that the tooling can be changed and so on. And as a company, that's what we do. But that's my recommendation to all systems out there. You get very serious about
 interfaces, and then you maintain them rigorously. You do not allow a tool to cheekily do things. Oh, yes, it's using sparkle and these other things. So sys lock has a couple of weird endpoints that the system uses. That means that system is bound to sys lock now. Oh, I'll let you go. No worries. Because you've totally picked Brian. It's been really good though. Very good. Well, very happy to talk about this. It's what I love to do.
 Yes. Nah, it's good. Yep. You're given heaps to think about. Nice and pragmatic as well. I do have to send you an email, by the way. It turns out that Tern have duplicated ANSYS vocabs and are publishing them.
