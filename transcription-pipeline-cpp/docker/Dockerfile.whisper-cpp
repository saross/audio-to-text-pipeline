# Clean whisper.cpp setup with CUDA support
FROM nvidia/cuda:12.2.0-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV CUDA_DOCKER_ARCH=all
ENV WHISPER_CUDA=1

# Use Australian mirror (since you're in Melbourne)
RUN sed -i 's|http://archive.ubuntu.com/ubuntu|http://au.archive.ubuntu.com/ubuntu|g' /etc/apt/sources.list && \
    sed -i 's|http://security.ubuntu.com/ubuntu|http://au.archive.ubuntu.com/ubuntu|g' /etc/apt/sources.list

# Install dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    cmake \
    libopenblas-dev \
    pkg-config \
    wget \
    ffmpeg \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Clone and build whisper.cpp with CUDA support
RUN git clone https://github.com/ggerganov/whisper.cpp.git && \
    cd whisper.cpp && \
    cmake -B build -DGGML_CUDA=ON && \
    cmake --build build --config Release

# Download models
WORKDIR /app/whisper.cpp
RUN bash ./models/download-ggml-model.sh tiny.en && \
    bash ./models/download-ggml-model.sh base.en && \
    bash ./models/download-ggml-model.sh small.en && \
    bash ./models/download-ggml-model.sh medium.en

# Install Python dependencies
RUN pip3 install pyyaml

# Copy the transcription wrapper script
WORKDIR /app
COPY transcribe.py /app/transcribe.py
RUN chmod +x /app/transcribe.py

# Test nvidia-smi is available
RUN which nvidia-smi || echo "nvidia-smi not found in PATH"

# Set entrypoint
ENTRYPOINT ["python3", "/app/transcribe.py"]
CMD ["--help"]